# ü§ñ AI Framework Setup Guide

## ‚ú® Complete AI Pipeline

Your Flrt keyboard now has a **professional, modular AI processing framework**!

---

## üìã Architecture Overview

```
Screenshot ‚Üí Keyboard ‚Üí Shared Container ‚Üí Main App
                                              ‚Üì
                                         AI Request
                                              ‚Üì
                                     AI Service Manager
                                              ‚Üì
                                      OpenAI Service
                                              ‚Üì
                                     Response Parser
                                              ‚Üì
                                      JSON Response
                                              ‚Üì
                                Keyboard Display (3 bubbles)
```

---

## üìÅ Project Structure

### **Models/** (`flrt/Models/`)
- `AIModels.swift` - All data structures
  - `AIRequest` - Image + prompt ‚Üí AI
  - `AIResponse` - Raw API response
  - `ParsedResponse` - Structured suggestions
  - `MessageSuggestion` - Individual bubble

### **Services/** (`flrt/Services/`)
- `AIService.swift` - Protocol + Manager
- `OpenAIService.swift` - OpenAI GPT-4 Vision
- `ResponseParser.swift` - JSON/text parsing

### **Config/** (`flrt/Config/`)
- `APIConfiguration.swift` - API keys + keychain

### **Networking/** (`flrt/Networking/`)
- `NetworkManager.swift` - HTTP requests

---

## üîë Setup Instructions

### 1. Get Your OpenAI API Key

1. Go to https://platform.openai.com/api-keys
2. Create new API key
3. Copy the key (starts with `sk-`)

### 2. Add API Key to Your App

**Option A: Info.plist (Quick)**
```xml
<!-- Add to flrt/Info.plist -->
<key>OPENAI_API_KEY</key>
<string>sk-your-actual-key-here</string>
```

**Option B: Environment Variable (Development)**
```bash
export OPENAI_API_KEY="sk-your-actual-key-here"
```

**Option C: Keychain (Production - Secure)**
```swift
// In your app setup
APIConfiguration.shared.setOpenAIKey("sk-your-actual-key-here")
```

### 3. Build and Run

The framework will automatically:
- ‚úÖ Load your API key
- ‚úÖ Initialize AI services
- ‚úÖ Process screenshots
- ‚úÖ Display AI suggestions

---

## üéØ How It Works

### 1. Image Capture
```swift
// Keyboard auto-detects screenshots
// Crops to remove keyboard area
// Saves to shared container
```

### 2. AI Request
```swift
let request = AIRequest(image: screenshot)
let response = try await AIServiceManager.shared.processImage(request)
```

### 3. OpenAI Processing
```swift
// Sends image + prompt to GPT-4 Vision
// System prompt: "Suggest 3 text message responses"
// Returns JSON with suggestions
```

### 4. Response Parsing
```swift
// Parses JSON response
// Extracts 3 suggestions
// Fallback to plain text if needed
```

### 5. Display in Keyboard
```swift
// Updates 3 blue bubbles
// Updates context (gray bubble)
// Shows in iMessage-style layout
```

---

## üé® Customization

### Change System Prompt

Edit `AIModels.swift`:
```swift
static let defaultSystemPrompt = """
Your custom instructions here...
"""
```

### Change Model

Edit `OpenAIService.swift`:
```swift
private let model = "gpt-4o" // or "gpt-4-vision-preview"
```

### Add New AI Provider

1. Create new service (e.g., `ClaudeService.swift`)
2. Implement `AIService` protocol
3. Set as active:
```swift
AIServiceManager.shared.setService(ClaudeService())
```

---

## üìä Data Flow

### Request Format
```json
{
  "model": "gpt-4o",
  "messages": [
    {
      "role": "system",
      "content": "Analyze and suggest responses..."
    },
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "Suggest responses"},
        {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}}
      ]
    }
  ]
}
```

### Response Format (AI ‚Üí Keyboard)
```json
{
  "suggestions": [
    {"text": "That's amazing!", "category": "casual"},
    {"text": "Interesting perspective", "category": "thoughtful"},
    {"text": "Thanks for sharing!", "category": "engaging"}
  ],
  "context": "Image shows a news article about...",
  "timestamp": 1234567890.123
}
```

---

## üõ°Ô∏è Error Handling

### API Key Missing
```
"API key not configured"
"Please check app settings"
"Unable to process image"
```

### Rate Limit
```
"Rate limit reached"
"Please try again later"
"Service temporarily unavailable"
```

### Generic Error
```
"That's interesting!"
"Thanks for sharing"
"What do you think?"
```

---

## üîê Security

### API Key Storage
- ‚úÖ **Keychain**: Most secure (production)
- ‚ö†Ô∏è **Info.plist**: Convenient (development only)
- ‚ùå **Hardcoded**: Never do this

### Best Practices
```swift
// Good
APIConfiguration.shared.setOpenAIKey(userEnteredKey)

// Bad
let apiKey = "sk-1234..." // Don't hardcode!
```

---

## üìà Performance

### Image Optimization
- Cropped to remove keyboard (smaller size)
- JPEG compression 0.8 (balance quality/size)
- Base64 encoding for API

### Response Time
- Typical: 2-5 seconds
- Network: 1-2s
- AI Processing: 1-3s
- Parsing: <0.1s

### Caching (Future)
- Cache similar screenshots
- Reuse recent responses
- Reduce API calls

---

## üß™ Testing

### Test Without API Key
```swift
// Keyboard will show fallback responses
"That's interesting!"
"Thanks for sharing"
"What do you think?"
```

### Test With API Key
1. Add key to Info.plist
2. Build and run on device
3. Take screenshot
4. Open keyboard
5. See AI-generated responses!

### Debug Logs
```
üì∏ Processing image: screenshot_123.jpg
ü§ñ Processing image with OpenAI GPT-4 Vision...
üîç Parsing AI response...
‚úÖ AI Processing complete!
   Suggestions: 3
   Context: Image shows...
‚úÖ Updated bubbles with AI suggestions
```

---

## üöÄ Production Checklist

- [ ] API key stored in keychain
- [ ] Error handling tested
- [ ] Rate limiting handled
- [ ] Fallback responses work
- [ ] Network errors handled
- [ ] User feedback clear
- [ ] Logs don't expose keys
- [ ] Info.plist keys removed

---

## üí° Future Enhancements

### Phase 1 (Current)
- ‚úÖ Screenshot capture
- ‚úÖ OpenAI GPT-4 Vision
- ‚úÖ 3 text suggestions
- ‚úÖ JSON parsing
- ‚úÖ Error handling

### Phase 2
- [ ] Multiple AI providers (Claude, Gemini)
- [ ] Custom prompts per screenshot
- [ ] Response history
- [ ] Tap to insert text

### Phase 3
- [ ] Local AI (on-device)
- [ ] Response caching
- [ ] User preferences
- [ ] Analytics

---

## üÜò Troubleshooting

### "API key not configured"
‚Üí Add key to Info.plist or keychain

### "Rate limit exceeded"
‚Üí OpenAI free tier limits reached

### "Network error"
‚Üí Check internet connection

### "Invalid response"
‚Üí Check OpenAI API status

### Bubbles show sample text
‚Üí Check console for errors
‚Üí Verify API key is correct

---

## üìû Support

### Logs
Enable detailed logging:
```swift
// Check Xcode console for:
print("üì∏ ...") // Image processing
print("ü§ñ ...") // AI service
print("üîç ...") // Parsing
print("‚úÖ ...") // Success
print("‚ùå ...") // Errors
```

### Common Issues
1. **Key not loading**: Check Info.plist format
2. **Parsing fails**: Check JSON structure
3. **Slow responses**: Normal for AI processing
4. **Wrong suggestions**: Adjust system prompt

---

## üéâ You're Ready!

Your AI framework is:
- ‚úÖ Modular and extensible
- ‚úÖ Production-ready
- ‚úÖ Error-resistant
- ‚úÖ Well-documented

Just add your OpenAI API key and start getting AI-powered suggestions! üöÄ

